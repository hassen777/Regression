{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: Saving and restoring models in Python\n",
    "Â© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we learn about pickling for saving and restoring a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "* Learn how to load standard sklearn datasets.\n",
    "* Understand the principle of object serialisation.\n",
    "* Learn how to save and restore an sklearn model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Once a model is trained, it is best to **separate the model from the training code** and use it to make predictions going forward. This ensures the model is lightweight and efficient to put into **production**. \n",
    "\n",
    "We often do this by **'saving'** the model: \n",
    "\n",
    ">Saving a model entails storing its parameters and all information needed to make predictions.\n",
    "\n",
    "For example, in the case of a model represented as `y = ax + b`, we would save the `a` and `b` parameters and the fact that it is a linear model.\n",
    "\n",
    "At this point in the course, you should be familiar with how to train, test, and measure the performance of various machine learning models on a given dataset. In this train we cover how to **save** your models into a portable format and **deploy** them in the wild."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and data\n",
    "\n",
    "Let's **import** a few Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the **diabetes built-in dataset** which contains a set of predictive variables for predicting some quantitative measure of diabetes disease progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **data description** can be shown as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 442\n",
      "\n",
      ":Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      ":Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      ":Attribute Information:\n",
      "    - age     age in years\n",
      "    - sex\n",
      "    - bmi     body mass index\n",
      "    - bp      average blood pressure\n",
      "    - s1      tc, total serum cholesterol\n",
      "    - s2      ldl, low-density lipoproteins\n",
      "    - s3      hdl, high-density lipoproteins\n",
      "    - s4      tch, total cholesterol / HDL\n",
      "    - s5      ltg, possibly log of serum triglycerides level\n",
      "    - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **create a DataFrame** using the data we have loaded above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['progression'] = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  progression  \n",
       "0 -0.002592  0.019907 -0.017646        151.0  \n",
       "1 -0.039493 -0.068332 -0.092204         75.0  \n",
       "2 -0.002592  0.002861 -0.025930        141.0  \n",
       "3  0.034309  0.022688 -0.009362        206.0  \n",
       "4 -0.002592 -0.031988 -0.046641        135.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training the model\n",
    "\n",
    "Let's start by training a model that we can save later.  We'll build a **multiple linear regression** model on the sklearn's internal dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Having reviewed the data, we now perform a minimal amount of preprocessing to **prepare for model fitting** and **evaluation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "y = df['progression']\n",
    "X = df.drop('progression',axis=1)\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# get training and testing data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting and evaluation\n",
    "\n",
    "We now fit our model to the data. For this example, we choose a **vanilla linear regression model**, however, we can still explore more complex models within `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model \n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get predictions on the test set \n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate performance metrics\n",
    "print(\"MSE:\",mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where visualising how the model performs on the actual data is not possible (i.e. too many dimensions), we can plot the actual vs. the predicted `ð¦` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred) \n",
    "plt.plot(y_test,y_test,\"r\") # perfect model line\n",
    "plt.ylabel(\"Predicted $y$\")\n",
    "plt.xlabel(\"Actual $y$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a glance, our MLR model seems to have decent performance. Now let's try to save it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Object serialisation\n",
    "\n",
    "Object serialisation is the **storing of variables** and **their values** as a **file**. \n",
    "\n",
    "If we save a standard Python program (i.e. `.py` file), the program needs to be executed before variables can realise their values. \n",
    "\n",
    "For example, think of a saved Jupyter Notebook file (`.ipynb`) where we have to **re-execute all program cells** before we can continue working on our program. \n",
    "\n",
    "In the context of machine learning models, this means we have to **re-train our models** on the original train data before we can use them on other unseen data. \n",
    "\n",
    ">Object serialisation allows us to store our variables and their state as a file, which upon loading can restore the variable and the value it had when we saved it. \n",
    "\n",
    "This way, we can **save** our **sklearn models** along with **their optimal parameters** and **load** them later for reuse.\n",
    "\n",
    "In this train, we will explore **`pickle`**, a common Python library for object serialisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model with Pickle\n",
    "\n",
    "Files saved using `pickle` are called ***pickles*** and the process of making them is referred to as ***pickling*** (we know, they took the metaphor quite far...). \n",
    "\n",
    "Luckily for us, saving models using `pickle` follows a similar structure to that of creating or writing to a file in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pickle library\n",
    "import pickle\n",
    "\n",
    "# Save the model just like we would a Python file\n",
    "model_save_path = \"mlr_model.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a **portable `model.pkl` file** in the specified file path which we **can move** between computers, email to others, use for model versioning, etc. We can also use this file to **make predictions** in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring the model with Pickle\n",
    "\n",
    "As you might have guessed, restoring a pickled file is similar to reading a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the model just like we would read a file\n",
    "model_load_path = \"mlr_model.pkl\"\n",
    "with open(model_load_path,'rb') as file:\n",
    "    unpickled_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we have loaded our saved model from the load path and loaded it into the `unpickled_model` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model file to make predictions\n",
    "\n",
    "**NB:** Imagine that we are now starting on a new Jupyter Notebook and this was all we put in it.\n",
    "You will notice there is **no data** and **no training** in the code since the model is already trained and the training data are no longer needed.\n",
    "\n",
    "All that's left now is to **load the data into the model** and get predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from unpickled model\n",
    "y_pred = unpickled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have model predictions that we can use wherever we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate performance metrics\n",
    "print(\"MSE:\",mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to keep in mind\n",
    "\n",
    "In order to ensure that the behaviour of your **model is reproducible** after serialisation, you should keep the following in mind:\n",
    "\n",
    "- **The Python environment dependencies** (version of Python packages): Make sure the model is deployed into an identical environment, i.e. `sklearn` versions are the same as in the model training environment.\n",
    "\n",
    "- **The Python version**: It is unreasonable to expect a model trained using `Python 2.7` would work when restored to an environment with `Python 3.6`. As such, it is important to use consistent versions of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** A new version of the Pandas package, `Pandas 2`, was released in April 2023. While it comes with added functionality, we continue to use `Pandas 1` in this train for stability purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data - pass 'Name' as our index column.\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/fundamentals/football_players.csv', index_col='Name')\n",
    "\n",
    "# Use the head() function to look at the first 5 rows.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Serialising your models can be extremely useful. Not only can you **save** your models but you can also **re-train** them later when more data are available.  \n",
    "\n",
    "In this train, we covered how to:\n",
    "\n",
    "- Train a multiple linear regression model.\n",
    "- Save the model (i.e. trained model parameters) to a file.\n",
    "- Restore a saved model and use it to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
